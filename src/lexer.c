/**
 * @file lexer.c
 * @brief Functionality to do the lexical analysis of the asm file
 * @version 0.1
 * @date 2022-07-23
 *
 */

#include "../include/lc3.h"

static void free_tokens(char **tokens, bool is_label_line) {    
    if(is_label_line) {                      
        free(tokens - 1);
    }
    else {                
        free(tokens);
    }
}

/**
 * @brief Determine the type of a line based on the value of the first token
 *
 * @param first_token first token of the line being parsed
 * @return linetype_t value indicative of the type of line
 */
static linetype_t compute_line_type(const char *first_token) {

    linetype_t result;
    if(first_token[0] == '\n') {
        result = BLANK_LINE;
    }
    else if(
        strcmp(first_token, "ADD") == 0 ||
        strcmp(first_token, "AND") == 0 ||
        strcmp(first_token, "JMP") == 0 ||
        strcmp(first_token, "JSR") == 0 ||
        strcmp(first_token, "NOT") == 0 ||
        strcmp(first_token, "RET") == 0 ||
        strcmp(first_token, "HALT") == 0 ||
        strcmp(first_token, "LD") == 0 ||
        strcmp(first_token, "ST") == 0 ||
        strcmp(first_token, "LDI") == 0 ||
        strcmp(first_token, "STI") == 0 ||
        strcmp(first_token, "LEA") == 0 ||
        strcmp(first_token, "BR") == 0 ||
        strcmp(first_token, "BRnzp") == 0 ||
        strcmp(first_token, "BRnz") == 0 ||
        strcmp(first_token, "BRnp") == 0 ||
        strcmp(first_token, "BRzp") == 0 ||
        strcmp(first_token, "BRn") == 0 ||
        strcmp(first_token, "BRz") == 0 ||
        strcmp(first_token, "BRp") == 0
        ) {
        result = OPCODE;
    }
    else if(strcmp(first_token, ".ORIG") == 0) {
        result = ORIG_DIRECTIVE;
    }
    else if(strcmp(first_token, ".END") == 0) {
        result = END_DIRECTIVE;
    }
    else if(strcmp(first_token, ".FILL") == 0) {
        result = FILL_DIRECTIVE;
    }
    else if(first_token[0] == ';') {
        result = COMMENT;
    }
    else {
        //any unrecognised token is considered to be a label
        result = LABEL;
    }

    return result;
}

/**
 * @brief do the lexical analysis of the asm file
 * 
 * Each line is analyzed separately: lines corresponding to instructions/directives are split into tokens and stored as
 * an element of the array `tokenized_lines`.
 * The symbol table is also created to store the offset of the different labels found during the analysis.
 * 
 * This function does not perform any syntactic validation and as a consequence the lexer is not aware of the existence 
 * or not of the .ORIG directive. That's why the resulting symbol table only stores offsets instead of the actual memory locations.
 * 
 * Actual memory locations will be determined during syntactic/semantic analysis by adding the previous offsets to the reference
 * memory address given by .ORIG.
 * 
 * @param assembly_file handle to the asm file
 * @param tokenized_lines array to store line metadata generated by the lexer
 * @return exit_t 
 */
exit_t do_lexical_analysis(FILE *assembly_file, linemetadata_t *tokenized_lines[]) {    
    //pointer to the current line
    //on each iteration of the while loop, the value is overwritten with the contents of the current line    
    char *resusable_line = NULL;
    size_t len = 0; //length of the current line

    memaddr_t location_counter = 0; //location in memory assigned to each instruction
    int line_counter = 0; //current line number in the assembly file

    errno = 0;
    ssize_t read;
    while((read = getline(&resusable_line, &len, assembly_file)) != -1) {
        printf("%s", resusable_line);
        bool is_label_line = false;
        line_counter++;

        char *line = strdup(resusable_line);
        int num_tokens = 0;
        char **tokens = split_tokens2(line, &num_tokens, " ,\n");
        if(num_tokens == 0) {               
            free(line);         
            continue;
        }

        linetype_t line_type = compute_line_type(tokens[0]);
        if(line_type == LABEL) {
            add(tokens[0], location_counter);
            if(num_tokens > 1) {
                //continue processing the rest of the line as there are more elements after the label
                tokens++;
                num_tokens--;
                is_label_line = true;
                line_type = compute_line_type(tokens[0]);
            }
            else {
                free(line);
                free(tokens);
                continue;
            }
        }

        if(line_type == END_DIRECTIVE) {
            free(line);
            free_tokens(tokens, is_label_line);
            //stop reading file
            break;
        }
        else if(line_type == COMMENT || line_type == BLANK_LINE) {  
            free(line);          
            free_tokens(tokens, is_label_line);
            //ignore line
            continue;
        }

        linemetadata_t *linemetadata = malloc(sizeof(linemetadata_t));
        if(!linemetadata) {
            //out of memory error
        }
        linemetadata->tokens = tokens;
        linemetadata->num_tokens = num_tokens;
        linemetadata->is_label_line = is_label_line;
        linemetadata->line = line;
        tokenized_lines[location_counter] = linemetadata;        
        location_counter++;
    }

    free(resusable_line);
    //check if getline resulted in error
    if(read == -1 && errno) {
        return do_exit(EXIT_FAILURE, "getLine error %d\n", errno);
    }

    return success();
}
